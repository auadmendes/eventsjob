2025-06-16 14:34:29,478 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-16 14:35:29,507 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-16 14:35:29,508 - event_scraper - INFO - Hi, it worked! The scrape_and_save_events function was called at Mon Jun 16 14:35:29 2025
2025-06-16 14:35:29,510 - event_scraper_log - INFO - Event scraping job completed successfully.
2025-06-16 14:36:29,543 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-16 14:36:29,545 - event_scraper - INFO - Hi, it worked! The scrape_and_save_events function was called at Mon Jun 16 14:36:29 2025
2025-06-16 14:36:29,546 - event_scraper_log - INFO - Event scraping job completed successfully.
2025-06-16 14:37:29,588 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-16 14:37:29,590 - event_scraper - INFO - Hi, it worked! The scrape_and_save_events function was called at Mon Jun 16 14:37:29 2025
2025-06-16 14:37:29,591 - event_scraper_log - INFO - Event scraping job completed successfully.
2025-06-16 14:38:29,622 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-16 14:38:29,622 - event_scraper - INFO - Hi, it worked! The scrape_and_save_events function was called at Mon Jun 16 14:38:29 2025
2025-06-16 14:38:29,624 - event_scraper_log - INFO - Event scraping job completed successfully.
2025-06-16 14:38:44,907 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-16 20:32:13,742 - event_scraper - ERROR - Failed to fetch page: HTTPSConnectionPool(host='www.sympla.com.br', port=443): Max retries exceeded with url: /eventos/vitoria-es/mais-vistos/entretenimento-dia?ordem=start-date (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1028)')))
2025-06-16 20:32:55,845 - event_scraper - ERROR - Failed to fetch page: HTTPSConnectionPool(host='www.sympla.com.br', port=443): Max retries exceeded with url: /eventos/vitoria-es/mais-vistos/entretenimento-dia?ordem=start-date (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1028)')))
2025-06-16 20:33:36,537 - event_scraper - INFO - Event: Pagodaço - Di Propósito
2025-06-16 20:33:36,547 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,547 - event_scraper - INFO - Event: Bailão Nerd - Edição Vila Velha/ES
2025-06-16 20:33:36,559 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,560 - event_scraper - INFO - Event: Rock dos Gêmeos
2025-06-16 20:33:36,578 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,580 - event_scraper - INFO - Event: FESTIVAL CASA CORAIS (10# Edição)
2025-06-16 20:33:36,599 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,600 - event_scraper - INFO - Event: ARRAIÁ DO BURBURINHO - ALVORADA
2025-06-16 20:33:36,615 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,616 - event_scraper - INFO - Event: Bailão Nerd - Edição Linhares/ES
2025-06-16 20:33:36,633 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,637 - event_scraper - INFO - Event: Medieval ES 4ª Edição - HERÓIS E DRAGÕES
2025-06-16 20:33:36,657 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,658 - event_scraper - INFO - Event: Arraiá do Rock
2025-06-16 20:33:36,670 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,671 - event_scraper - INFO - Event: Orquestra Camerata Sesi - Temporada Pop: Concerto Junino
2025-06-16 20:33:36,680 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,681 - event_scraper - INFO - Event: ESQUENTA DE ITAÚNAS do FORROZADA BOA - Vitória ES
2025-06-16 20:33:36,690 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,691 - event_scraper - INFO - Event: Noite sertaneja
2025-06-16 20:33:36,696 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,697 - event_scraper - INFO - Event: Bunker Fest Rock
2025-06-16 20:33:36,705 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,706 - event_scraper - INFO - Event: REVOLUTION 2025
2025-06-16 20:33:36,711 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,712 - event_scraper - INFO - Event: Cover Girl - Burlesque Edition
2025-06-16 20:33:36,715 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,715 - event_scraper - INFO - Event: LOUDER NIGHT
2025-06-16 20:33:36,724 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,725 - event_scraper - INFO - Event: Kaya Festival - 2 Edição
2025-06-16 20:33:36,731 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,732 - event_scraper - INFO - Event: Alien - The Cycle of the Stars
2025-06-16 20:33:36,741 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,742 - event_scraper - INFO - Event: Bloco da Teté
2025-06-16 20:33:36,747 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,748 - event_scraper - INFO - Event: Fritos sem fronteiras 2° edição
2025-06-16 20:33:36,757 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,758 - event_scraper - INFO - Event: Show Chico e Nina - Primaveras
2025-06-16 20:33:36,768 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,769 - event_scraper - INFO - Event: CLÃ 8º Edição
2025-06-16 20:33:36,779 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,780 - event_scraper - INFO - Event: ICELUCA CONVIDA
2025-06-16 20:33:36,788 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,788 - event_scraper - INFO - Event: Ambronelli - Cadu Caruzo
2025-06-16 20:33:36,794 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:33:36,795 - event_scraper - INFO - Event: Medusa Ink Fest
2025-06-16 20:33:36,799 - event_scraper - INFO - ------------------------------------------------------------
2025-06-16 20:56:17,352 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-16 20:57:17,388 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-16 20:57:18,452 - event_scraper_log - INFO - Event scraping job completed successfully.
2025-06-16 20:57:39,476 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-16 21:15:03,349 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-16 21:16:03,384 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-16 21:16:06,237 - event_scraper_log - INFO - Event scraping job completed successfully.
2025-06-16 21:17:06,272 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-16 21:17:07,616 - event_scraper_log - INFO - Event scraping job completed successfully.
2025-06-16 21:18:07,652 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-16 21:18:08,772 - event_scraper_log - INFO - Event scraping job completed successfully.
2025-06-16 21:18:16,489 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-16 21:24:18,208 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-16 21:25:18,242 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-16 21:25:23,465 - event_scraper_log - INFO - Event scraping job completed successfully.
2025-06-16 21:26:23,498 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-16 21:26:26,462 - event_scraper_log - INFO - Event scraping job completed successfully.
2025-06-16 21:27:26,495 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-16 21:27:29,628 - event_scraper_log - INFO - Event scraping job completed successfully.
2025-06-16 21:27:36,779 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-16 21:47:10,120 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-16 21:48:10,157 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-16 21:48:14,153 - event_scraper_log - INFO - Event scraping SYMPLA job completed successfully.
2025-06-16 21:48:17,106 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-16 21:49:14,815 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-16 21:55:26,942 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-16 21:56:26,978 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-16 21:56:31,293 - event_scraper_log - INFO - Event scraping SYMPLA job completed successfully.
2025-06-16 21:56:34,694 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-16 21:57:34,727 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-16 21:57:38,200 - event_scraper_log - INFO - Event scraping SYMPLA job completed successfully.
2025-06-16 21:57:41,727 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-16 21:58:19,550 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-17 08:36:34,332 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-17 08:37:34,364 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 08:37:39,323 - event_scraper_log - INFO - Event scraping SYMPLA job completed successfully.
2025-06-17 08:37:42,277 - event_scraper_log - ERROR - Error during event scraping job: cannot access local variable 'event_cards' where it is not associated with a value
Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 15, in run_event_scraping_job
    scrape_and_save_patrick_events()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 95, in scrape_and_save_patrick_events
    if not event_cards:
           ^^^^^^^^^^^
UnboundLocalError: cannot access local variable 'event_cards' where it is not associated with a value
2025-06-17 08:38:03,550 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-17 08:40:06,271 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-17 08:41:06,306 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 08:41:08,777 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-17 08:42:08,807 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 08:42:10,628 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-17 08:42:51,986 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-17 08:47:08,445 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-17 08:48:08,480 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 08:48:11,376 - event_scraper_log - ERROR - Error during event scraping job: batch op errors occurred, full error: {'writeErrors': [{'index': 7, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: eventsdb.events index: link_1 dup key: { link: "https://www.blueticket.com.br/evento/38040" }', 'keyPattern': {'link': 1}, 'keyValue': {'link': 'https://www.blueticket.com.br/evento/38040'}, 'op': {'title': 'Liga Joe – Flash Back anos 70, 80 e 90', 'location': 'Spaço Patrick Ribeiro', 'date': None, 'link': 'https://www.blueticket.com.br/evento/38040', 'image': 'https://patrickribeiro.com.br/wp-content/uploads/2025/06/17OUT-LIGA-JOE.png', '_id': ObjectId('685155fbd07cc5a9987d00ec')}}], 'writeConcernErrors': [], 'nInserted': 7, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}
Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 15, in run_event_scraping_job
    scrape_and_save_patrick_events()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 139, in scrape_and_save_patrick_events
    save_events_bulk(events_to_save)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\database\db_operations.py", line 31, in save_events_bulk
    events_collection.insert_many(new_events)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\_csot.py", line 125, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\collection.py", line 975, in insert_many
    blk.execute(write_concern, session, _Op.INSERT)
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\bulk.py", line 751, in execute
    return self.execute_command(generator, write_concern, session, operation)
           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\bulk.py", line 614, in execute_command
    _raise_bulk_write_error(full_result)
    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\bulk_shared.py", line 131, in _raise_bulk_write_error
    raise BulkWriteError(full_result)
pymongo.errors.BulkWriteError: batch op errors occurred, full error: {'writeErrors': [{'index': 7, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: eventsdb.events index: link_1 dup key: { link: "https://www.blueticket.com.br/evento/38040" }', 'keyPattern': {'link': 1}, 'keyValue': {'link': 'https://www.blueticket.com.br/evento/38040'}, 'op': {'title': 'Liga Joe – Flash Back anos 70, 80 e 90', 'location': 'Spaço Patrick Ribeiro', 'date': None, 'link': 'https://www.blueticket.com.br/evento/38040', 'image': 'https://patrickribeiro.com.br/wp-content/uploads/2025/06/17OUT-LIGA-JOE.png', '_id': ObjectId('685155fbd07cc5a9987d00ec')}}], 'writeConcernErrors': [], 'nInserted': 7, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}
2025-06-17 08:48:32,122 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-17 08:52:22,950 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-17 08:53:22,987 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 08:53:26,764 - event_scraper_log - ERROR - Error during event scraping job: name 'events_collection' is not defined
Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 15, in run_event_scraping_job
    scrape_and_save_patrick_events()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 105, in scrape_and_save_patrick_events
    event["link"] for event in events_collection.find(
                               ^^^^^^^^^^^^^^^^^
NameError: name 'events_collection' is not defined
2025-06-17 08:53:52,467 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-17 08:59:48,685 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-17 09:00:48,718 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 09:00:52,352 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-17 09:01:52,385 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 09:01:55,880 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-17 09:02:03,827 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-17 15:38:12,592 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-17 15:39:12,627 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 15:39:17,993 - event_scraper_log - INFO - Event scraping SYMPLA job completed successfully.
2025-06-17 15:39:21,217 - event_scraper_log - ERROR - Error during event scraping job: batch op errors occurred, full error: {'writeErrors': [{'index': 8, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: eventsdb.events index: link_1 dup key: { link: "https://www.blueticket.com.br/evento/38040" }', 'keyPattern': {'link': 1}, 'keyValue': {'link': 'https://www.blueticket.com.br/evento/38040'}, 'op': {'title': 'Liga Joe – Flash Back anos 70, 80 e 90', 'location': 'Espaço Patrick Ribeiro', 'date': None, 'link': 'https://www.blueticket.com.br/evento/38040', 'image': 'https://patrickribeiro.com.br/wp-content/uploads/2025/06/17OUT-LIGA-JOE.png', 'font': 'Espaço Patrick Ribeiro', 'category': 'Outros', 'UF': 'ES', '_id': ObjectId('6851b659b59055440a414a1f')}}], 'writeConcernErrors': [], 'nInserted': 8, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}
Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 16, in run_event_scraping_job
    scrape_and_save_patrick_events()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 162, in scrape_and_save_patrick_events
    save_events_bulk(events_to_save)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\database\db_operations.py", line 31, in save_events_bulk
    events_collection.insert_many(new_events)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\_csot.py", line 125, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\collection.py", line 975, in insert_many
    blk.execute(write_concern, session, _Op.INSERT)
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\bulk.py", line 751, in execute
    return self.execute_command(generator, write_concern, session, operation)
           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\bulk.py", line 614, in execute_command
    _raise_bulk_write_error(full_result)
    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\bulk_shared.py", line 131, in _raise_bulk_write_error
    raise BulkWriteError(full_result)
pymongo.errors.BulkWriteError: batch op errors occurred, full error: {'writeErrors': [{'index': 8, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: eventsdb.events index: link_1 dup key: { link: "https://www.blueticket.com.br/evento/38040" }', 'keyPattern': {'link': 1}, 'keyValue': {'link': 'https://www.blueticket.com.br/evento/38040'}, 'op': {'title': 'Liga Joe – Flash Back anos 70, 80 e 90', 'location': 'Espaço Patrick Ribeiro', 'date': None, 'link': 'https://www.blueticket.com.br/evento/38040', 'image': 'https://patrickribeiro.com.br/wp-content/uploads/2025/06/17OUT-LIGA-JOE.png', 'font': 'Espaço Patrick Ribeiro', 'category': 'Outros', 'UF': 'ES', '_id': ObjectId('6851b659b59055440a414a1f')}}], 'writeConcernErrors': [], 'nInserted': 8, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}
2025-06-17 15:40:21,259 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 15:40:24,144 - event_scraper_log - INFO - Event scraping SYMPLA job completed successfully.
2025-06-17 15:40:27,708 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-17 15:40:36,401 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-17 16:06:51,491 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-17 16:07:51,527 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 16:07:52,414 - event_scraper_log - INFO - Event scraping Beacons events job completed successfully.
2025-06-17 16:08:18,636 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-17 16:10:40,101 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-17 16:11:40,140 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 16:11:40,982 - event_scraper_log - INFO - Event scraping Beacons events job completed successfully.
2025-06-17 16:12:41,078 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 16:12:41,964 - event_scraper_log - INFO - Event scraping Beacons events job completed successfully.
2025-06-17 16:13:42,000 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 16:13:43,023 - event_scraper_log - INFO - Event scraping Beacons events job completed successfully.
2025-06-17 16:14:23,788 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-17 16:14:31,364 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-17 16:15:31,392 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 16:15:32,404 - event_scraper_log - INFO - Event scraping Beacons events job completed successfully.
2025-06-17 16:16:32,468 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 16:16:33,546 - event_scraper_log - INFO - Event scraping Beacons events job completed successfully.
2025-06-17 16:17:33,582 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 16:17:34,473 - event_scraper_log - INFO - Event scraping Beacons events job completed successfully.
2025-06-17 16:18:34,505 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 16:18:35,505 - event_scraper_log - INFO - Event scraping Beacons events job completed successfully.
2025-06-17 16:18:41,800 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-17 16:19:43,886 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-17 16:20:44,017 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 16:20:44,924 - event_scraper_log - INFO - Event scraping Beacons events job completed successfully.
2025-06-17 16:21:45,802 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 16:21:46,743 - event_scraper_log - INFO - Event scraping Beacons events job completed successfully.
2025-06-17 16:22:46,780 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 16:22:47,714 - event_scraper_log - INFO - Event scraping Beacons events job completed successfully.
2025-06-17 16:23:20,308 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-17 16:26:21,071 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-17 16:26:59,110 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-17 16:27:40,409 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-17 16:28:06,571 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-17 16:29:03,831 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-17 16:29:42,089 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-17 16:29:47,704 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-17 16:30:47,733 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-17 16:30:53,238 - event_scraper_log - INFO - Event scraping Beacons events job completed successfully.
2025-06-17 16:31:16,818 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-18 10:09:44,811 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-18 10:10:44,868 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 10:10:44,870 - event_scraper_log - INFO - Event scraping SYMPLA job completed successfully.
2025-06-18 10:10:44,871 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-18 10:10:48,394 - event_scraper_log - INFO - Event scraping SYMPLA Esportes job completed successfully.
2025-06-18 10:11:48,430 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 10:11:48,432 - event_scraper_log - INFO - Event scraping SYMPLA job completed successfully.
2025-06-18 10:11:48,433 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-18 10:11:50,274 - event_scraper_log - INFO - Event scraping SYMPLA Esportes job completed successfully.
2025-06-18 10:12:50,310 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 10:12:50,312 - event_scraper_log - INFO - Event scraping SYMPLA job completed successfully.
2025-06-18 10:12:50,313 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-18 10:12:52,523 - event_scraper_log - INFO - Event scraping SYMPLA Esportes job completed successfully.
2025-06-18 10:13:52,581 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 10:13:52,583 - event_scraper_log - INFO - Event scraping SYMPLA job completed successfully.
2025-06-18 10:13:52,585 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-18 10:13:54,878 - event_scraper_log - INFO - Event scraping SYMPLA Esportes job completed successfully.
2025-06-18 10:14:54,922 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 10:14:54,924 - event_scraper_log - INFO - Event scraping SYMPLA job completed successfully.
2025-06-18 10:14:54,925 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-18 10:14:57,020 - event_scraper_log - INFO - Event scraping SYMPLA Esportes job completed successfully.
2025-06-18 10:15:57,051 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 10:15:57,053 - event_scraper_log - INFO - Event scraping SYMPLA job completed successfully.
2025-06-18 10:15:57,055 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-18 10:15:59,116 - event_scraper_log - INFO - Event scraping SYMPLA Esportes job completed successfully.
2025-06-18 10:16:07,065 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-18 10:23:39,587 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-18 10:24:39,620 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 10:24:39,621 - event_scraper_log - INFO - Event scraping SYMPLA job completed successfully.
2025-06-18 10:24:39,622 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-18 10:24:41,258 - event_scraper_log - INFO - Event scraping SYMPLA Esportes job completed successfully.
2025-06-18 10:24:45,582 - event_scraper_log - INFO - Event scraping SYMPLA Comédia job completed successfully.
2025-06-18 10:25:45,614 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 10:25:45,615 - event_scraper_log - INFO - Event scraping SYMPLA job completed successfully.
2025-06-18 10:25:45,616 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-18 10:25:47,165 - event_scraper_log - INFO - Event scraping SYMPLA Esportes job completed successfully.
2025-06-18 10:25:50,268 - event_scraper_log - INFO - Event scraping SYMPLA Comédia job completed successfully.
2025-06-18 10:25:56,220 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-18 12:30:42,444 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-18 12:31:42,479 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 12:31:43,012 - event_scraper_log - INFO - Event scraping SYMPLA Comédia job completed successfully.
2025-06-18 12:32:43,049 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 12:32:43,589 - event_scraper_log - INFO - Event scraping SYMPLA Comédia job completed successfully.
2025-06-18 12:33:43,630 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 12:33:44,468 - event_scraper_log - INFO - Event scraping SYMPLA Comédia job completed successfully.
2025-06-18 12:33:47,464 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-18 12:39:24,130 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-18 12:40:24,280 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 12:40:24,818 - event_scraper_log - INFO - Event scraping SYMPLA Comédia job completed successfully.
2025-06-18 12:40:33,252 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-18 12:43:44,999 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-18 12:44:45,035 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 12:44:45,635 - event_scraper_log - INFO - Event scraping SYMPLA Comédia job completed successfully.
2025-06-18 12:44:53,719 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-18 12:47:02,578 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-18 12:48:02,615 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 12:48:03,090 - event_scraper_log - INFO - Event scraping SYMPLA Comédia job completed successfully.
2025-06-18 12:49:03,123 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 12:49:03,604 - event_scraper_log - INFO - Event scraping SYMPLA Comédia job completed successfully.
2025-06-18 12:49:21,290 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-18 12:54:51,900 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-18 12:55:51,935 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 12:55:51,937 - event_scraper_log - ERROR - Error during event scraping job: name 'Options' is not defined
Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 29, in run_event_scraping_job
    scrape_mapa_events()
    ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 609, in scrape_mapa_events
    chrome_options = Options()
                     ^^^^^^^
NameError: name 'Options' is not defined
2025-06-18 12:56:51,993 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 12:56:51,994 - event_scraper_log - ERROR - Error during event scraping job: name 'Options' is not defined
Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 29, in run_event_scraping_job
    scrape_mapa_events()
    ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 609, in scrape_mapa_events
    chrome_options = Options()
                     ^^^^^^^
NameError: name 'Options' is not defined
2025-06-18 12:57:12,547 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-18 12:57:22,595 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-18 12:58:22,633 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 12:58:40,234 - event_scraper_log - INFO - Event scraping SYMPLA Comédia job completed successfully.
2025-06-18 12:59:34,271 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-18 12:59:47,531 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-18 13:00:47,564 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 13:00:56,806 - event_scraper_log - INFO - Event scraping SYMPLA Comédia job completed successfully.
2025-06-18 13:01:01,101 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-18 13:09:02,208 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-18 13:10:02,248 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 13:10:17,651 - event_scraper_log - INFO - Event scraping SYMPLA Comédia job completed successfully.
2025-06-18 13:10:51,206 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-18 15:44:24,991 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-18 15:45:25,035 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 15:45:39,087 - event_scraper_log - ERROR - Error during event scraping job: batch op errors occurred, full error: {'writeErrors': [{'index': 4, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: eventsdb.events index: link_1 dup key: { link: "https://mapa.cultura.es.gov.br/evento/1409/" }', 'keyPattern': {'link': 1}, 'keyValue': {'link': 'https://mapa.cultura.es.gov.br/evento/1409/'}, 'op': {'title': '25º FESTIVAL NACIONAL DE TEATRO DE GUAÇUÍ', 'location': 'Espaço cultural Gota, Pó e Poeira', 'date': '23 de junho às 17:00', 'link': 'https://mapa.cultura.es.gov.br/evento/1409/', 'image': 'https://mapa.cultura.es.gov.br/files/event/1409/file/979016/whatsapp-image-2025-05-29-at-10-26-36-fa914ca8e5101951959ddbf3259eecff.jpeg', 'font': 'Mapa Cultural ES', 'category': 'Teatro', 'UF': 'ES', '_id': ObjectId('6853095302962ce63347b96f')}}], 'writeConcernErrors': [], 'nInserted': 4, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}
Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 29, in run_event_scraping_job
    scrape_mapa_events()
    ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 669, in scrape_mapa_events
    save_events_bulk(future_events)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\database\db_operations.py", line 31, in save_events_bulk
    events_collection.insert_many(new_events)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\_csot.py", line 125, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\collection.py", line 975, in insert_many
    blk.execute(write_concern, session, _Op.INSERT)
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\bulk.py", line 751, in execute
    return self.execute_command(generator, write_concern, session, operation)
           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\bulk.py", line 614, in execute_command
    _raise_bulk_write_error(full_result)
    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\bulk_shared.py", line 131, in _raise_bulk_write_error
    raise BulkWriteError(full_result)
pymongo.errors.BulkWriteError: batch op errors occurred, full error: {'writeErrors': [{'index': 4, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: eventsdb.events index: link_1 dup key: { link: "https://mapa.cultura.es.gov.br/evento/1409/" }', 'keyPattern': {'link': 1}, 'keyValue': {'link': 'https://mapa.cultura.es.gov.br/evento/1409/'}, 'op': {'title': '25º FESTIVAL NACIONAL DE TEATRO DE GUAÇUÍ', 'location': 'Espaço cultural Gota, Pó e Poeira', 'date': '23 de junho às 17:00', 'link': 'https://mapa.cultura.es.gov.br/evento/1409/', 'image': 'https://mapa.cultura.es.gov.br/files/event/1409/file/979016/whatsapp-image-2025-05-29-at-10-26-36-fa914ca8e5101951959ddbf3259eecff.jpeg', 'font': 'Mapa Cultural ES', 'category': 'Teatro', 'UF': 'ES', '_id': ObjectId('6853095302962ce63347b96f')}}], 'writeConcernErrors': [], 'nInserted': 4, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}
2025-06-18 15:46:39,137 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 15:46:50,006 - event_scraper_log - ERROR - Error during event scraping job: batch op errors occurred, full error: {'writeErrors': [{'index': 2, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: eventsdb.events index: link_1 dup key: { link: "https://mapa.cultura.es.gov.br/evento/1302/" }', 'keyPattern': {'link': 1}, 'keyValue': {'link': 'https://mapa.cultura.es.gov.br/evento/1302/'}, 'op': {'title': 'Encantarias - 1º Encontro de música intuitiva e integrativa do ES', 'location': 'Espaço Kabana Kebra Mar', 'date': '29 de junho às 09:00', 'link': 'https://mapa.cultura.es.gov.br/evento/1302/', 'image': 'https://mapa.cultura.es.gov.br/files/event/1302/file/941168/encantarias-post-para-instagram-76f066cfec9c5dc443681aa6158b9382.png', 'font': 'Mapa Cultural ES', 'category': 'Teatro', 'UF': 'ES', '_id': ObjectId('6853099902962ce63347b97f')}}], 'writeConcernErrors': [], 'nInserted': 2, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}
Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 29, in run_event_scraping_job
    scrape_mapa_events()
    ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 669, in scrape_mapa_events
    save_events_bulk(future_events)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\database\db_operations.py", line 31, in save_events_bulk
    events_collection.insert_many(new_events)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\_csot.py", line 125, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\collection.py", line 975, in insert_many
    blk.execute(write_concern, session, _Op.INSERT)
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\bulk.py", line 751, in execute
    return self.execute_command(generator, write_concern, session, operation)
           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\bulk.py", line 614, in execute_command
    _raise_bulk_write_error(full_result)
    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\bulk_shared.py", line 131, in _raise_bulk_write_error
    raise BulkWriteError(full_result)
pymongo.errors.BulkWriteError: batch op errors occurred, full error: {'writeErrors': [{'index': 2, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: eventsdb.events index: link_1 dup key: { link: "https://mapa.cultura.es.gov.br/evento/1302/" }', 'keyPattern': {'link': 1}, 'keyValue': {'link': 'https://mapa.cultura.es.gov.br/evento/1302/'}, 'op': {'title': 'Encantarias - 1º Encontro de música intuitiva e integrativa do ES', 'location': 'Espaço Kabana Kebra Mar', 'date': '29 de junho às 09:00', 'link': 'https://mapa.cultura.es.gov.br/evento/1302/', 'image': 'https://mapa.cultura.es.gov.br/files/event/1302/file/941168/encantarias-post-para-instagram-76f066cfec9c5dc443681aa6158b9382.png', 'font': 'Mapa Cultural ES', 'category': 'Teatro', 'UF': 'ES', '_id': ObjectId('6853099902962ce63347b97f')}}], 'writeConcernErrors': [], 'nInserted': 2, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}
2025-06-18 15:47:50,047 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 15:48:00,457 - event_scraper_log - ERROR - Error during event scraping job: batch op errors occurred, full error: {'writeErrors': [{'index': 2, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: eventsdb.events index: link_1 dup key: { link: "https://mapa.cultura.es.gov.br/evento/1403/" }', 'keyPattern': {'link': 1}, 'keyValue': {'link': 'https://mapa.cultura.es.gov.br/evento/1403/'}, 'op': {'title': 'Roda de Boteco 2025', 'location': 'Shopping Vila Velha', 'date': '12 de julho às 15:00', 'link': 'https://mapa.cultura.es.gov.br/evento/1403/', 'image': 'https://mapa.cultura.es.gov.br/files/event/1403/file/975494/roda-07c74f7d441626e4e4c4584dc2b5bf21.png', 'font': 'Mapa Cultural ES', 'category': 'Outros', 'UF': 'ES', '_id': ObjectId('685309e002962ce63347b985')}}], 'writeConcernErrors': [], 'nInserted': 2, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}
Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 29, in run_event_scraping_job
    scrape_mapa_events()
    ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 669, in scrape_mapa_events
    save_events_bulk(future_events)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\database\db_operations.py", line 31, in save_events_bulk
    events_collection.insert_many(new_events)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\_csot.py", line 125, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\collection.py", line 975, in insert_many
    blk.execute(write_concern, session, _Op.INSERT)
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\bulk.py", line 751, in execute
    return self.execute_command(generator, write_concern, session, operation)
           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\bulk.py", line 614, in execute_command
    _raise_bulk_write_error(full_result)
    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\bulk_shared.py", line 131, in _raise_bulk_write_error
    raise BulkWriteError(full_result)
pymongo.errors.BulkWriteError: batch op errors occurred, full error: {'writeErrors': [{'index': 2, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: eventsdb.events index: link_1 dup key: { link: "https://mapa.cultura.es.gov.br/evento/1403/" }', 'keyPattern': {'link': 1}, 'keyValue': {'link': 'https://mapa.cultura.es.gov.br/evento/1403/'}, 'op': {'title': 'Roda de Boteco 2025', 'location': 'Shopping Vila Velha', 'date': '12 de julho às 15:00', 'link': 'https://mapa.cultura.es.gov.br/evento/1403/', 'image': 'https://mapa.cultura.es.gov.br/files/event/1403/file/975494/roda-07c74f7d441626e4e4c4584dc2b5bf21.png', 'font': 'Mapa Cultural ES', 'category': 'Outros', 'UF': 'ES', '_id': ObjectId('685309e002962ce63347b985')}}], 'writeConcernErrors': [], 'nInserted': 2, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}
2025-06-18 15:49:00,492 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 15:49:03,760 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-18 21:02:48,510 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-18 21:03:48,541 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 21:04:08,972 - event_scraper_log - INFO - Event scraping SYMPLA job completed successfully.
2025-06-18 21:04:38,357 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-18 21:08:34,864 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-18 21:09:34,897 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 21:09:44,313 - event_scraper_log - INFO - Event scraping SYMPLA job completed successfully.
2025-06-18 21:10:31,401 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-18 21:13:23,646 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-18 21:14:23,678 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 21:14:40,318 - event_scraper_log - ERROR - Error during event scraping job: batch op errors occurred, full error: {'writeErrors': [{'index': 237, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: eventsdb.events index: link_1 dup key: { link: "https://www.sympla.com.br/evento/aula-filial-viva-velha-viver-significativamente-morrer-com-alegria/3004385" }', 'keyPattern': {'link': 1}, 'keyValue': {'link': 'https://www.sympla.com.br/evento/aula-filial-viva-velha-viver-significativamente-morrer-com-alegria/3004385'}, 'op': {'title': 'Aula Filial Viva Velha: Viver significativamente, morrer com alegria', 'location': 'Espaço Marzen - Vila Velha , ES', 'date': '2025-07-26T10:00:00', 'link': 'https://www.sympla.com.br/evento/aula-filial-viva-velha-viver-significativamente-morrer-com-alegria/3004385', 'image': 'https://images.sympla.com.br/6853180c30330-xs.jpg', 'font': 'Sympla', 'category': 'Cursos e Workshops', 'UF': 'ES', '_id': ObjectId('6853566f746bc8934d352306')}}], 'writeConcernErrors': [], 'nInserted': 237, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}
Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 13, in run_event_scraping_job
    scrape_and_save_events_sympla() # Call your main scraping function
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 214, in scrape_and_save_events_sympla
    save_events_bulk(all_events_to_save)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\database\db_operations.py", line 31, in save_events_bulk
    events_collection.insert_many(new_events)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\_csot.py", line 125, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\collection.py", line 975, in insert_many
    blk.execute(write_concern, session, _Op.INSERT)
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\bulk.py", line 751, in execute
    return self.execute_command(generator, write_concern, session, operation)
           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\bulk.py", line 614, in execute_command
    _raise_bulk_write_error(full_result)
    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\bulk_shared.py", line 131, in _raise_bulk_write_error
    raise BulkWriteError(full_result)
pymongo.errors.BulkWriteError: batch op errors occurred, full error: {'writeErrors': [{'index': 237, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: eventsdb.events index: link_1 dup key: { link: "https://www.sympla.com.br/evento/aula-filial-viva-velha-viver-significativamente-morrer-com-alegria/3004385" }', 'keyPattern': {'link': 1}, 'keyValue': {'link': 'https://www.sympla.com.br/evento/aula-filial-viva-velha-viver-significativamente-morrer-com-alegria/3004385'}, 'op': {'title': 'Aula Filial Viva Velha: Viver significativamente, morrer com alegria', 'location': 'Espaço Marzen - Vila Velha , ES', 'date': '2025-07-26T10:00:00', 'link': 'https://www.sympla.com.br/evento/aula-filial-viva-velha-viver-significativamente-morrer-com-alegria/3004385', 'image': 'https://images.sympla.com.br/6853180c30330-xs.jpg', 'font': 'Sympla', 'category': 'Cursos e Workshops', 'UF': 'ES', '_id': ObjectId('6853566f746bc8934d352306')}}], 'writeConcernErrors': [], 'nInserted': 237, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}
2025-06-18 21:15:35,685 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-18 21:26:33,109 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-18 21:27:33,144 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 21:27:48,462 - event_scraper_log - ERROR - Error during event scraping job: batch op errors occurred, full error: {'writeErrors': [{'index': 278, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: eventES.events index: link_1 dup key: { link: "https://www.sympla.com.br/evento/science-mapping-para-doutorado-mestrado-pos-tcc-ic-jcr-pesquisa-inovacao-tipo-20-a/2988689" }', 'keyPattern': {'link': 1}, 'keyValue': {'link': 'https://www.sympla.com.br/evento/science-mapping-para-doutorado-mestrado-pos-tcc-ic-jcr-pesquisa-inovacao-tipo-20-a/2988689'}, 'op': {'title': 'Science Mapping para Doutorado, Mestrado, Pós, TCC, IC, JCR, Pesquisa, Inovação - Tipo 20 A', 'location': 'CCJE - UFES - Ed. VI, sala 618 - Vitória , ES', 'date': '2025-06-25T08:00:00', 'link': 'https://www.sympla.com.br/evento/science-mapping-para-doutorado-mestrado-pos-tcc-ic-jcr-pesquisa-inovacao-tipo-20-a/2988689', 'image': 'https://images.sympla.com.br/6841de123afa0-xs.jpg', 'font': 'Sympla', 'category': 'Outros', 'UF': 'ES', '_id': ObjectId('68535983509821333b07ed28')}}], 'writeConcernErrors': [], 'nInserted': 278, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}
Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 13, in run_event_scraping_job
    scrape_and_save_events_sympla() # Call your main scraping function
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 213, in scrape_and_save_events_sympla
    save_events_bulk(all_events_to_save)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\database\db_operations.py", line 31, in save_events_bulk
    events_collection.insert_many(new_events)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\_csot.py", line 125, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\collection.py", line 975, in insert_many
    blk.execute(write_concern, session, _Op.INSERT)
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\bulk.py", line 751, in execute
    return self.execute_command(generator, write_concern, session, operation)
           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\bulk.py", line 614, in execute_command
    _raise_bulk_write_error(full_result)
    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\bulk_shared.py", line 131, in _raise_bulk_write_error
    raise BulkWriteError(full_result)
pymongo.errors.BulkWriteError: batch op errors occurred, full error: {'writeErrors': [{'index': 278, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: eventES.events index: link_1 dup key: { link: "https://www.sympla.com.br/evento/science-mapping-para-doutorado-mestrado-pos-tcc-ic-jcr-pesquisa-inovacao-tipo-20-a/2988689" }', 'keyPattern': {'link': 1}, 'keyValue': {'link': 'https://www.sympla.com.br/evento/science-mapping-para-doutorado-mestrado-pos-tcc-ic-jcr-pesquisa-inovacao-tipo-20-a/2988689'}, 'op': {'title': 'Science Mapping para Doutorado, Mestrado, Pós, TCC, IC, JCR, Pesquisa, Inovação - Tipo 20 A', 'location': 'CCJE - UFES - Ed. VI, sala 618 - Vitória , ES', 'date': '2025-06-25T08:00:00', 'link': 'https://www.sympla.com.br/evento/science-mapping-para-doutorado-mestrado-pos-tcc-ic-jcr-pesquisa-inovacao-tipo-20-a/2988689', 'image': 'https://images.sympla.com.br/6841de123afa0-xs.jpg', 'font': 'Sympla', 'category': 'Outros', 'UF': 'ES', '_id': ObjectId('68535983509821333b07ed28')}}], 'writeConcernErrors': [], 'nInserted': 278, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}
2025-06-18 21:28:21,997 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-18 21:40:13,253 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-18 21:41:13,292 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 21:41:29,672 - event_scraper_log - ERROR - Error during event scraping job: batch op errors occurred, full error: {'writeErrors': [{'index': 209, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: eventES.events index: link_1 dup key: { link: "https://www.sympla.com.br/evento/titela-em-ai-dentu-no-corone-mall-serra-es/2988972" }', 'keyPattern': {'link': 1}, 'keyValue': {'link': 'https://www.sympla.com.br/evento/titela-em-ai-dentu-no-corone-mall-serra-es/2988972'}, 'op': {'title': 'Titela em "AÍ DENTU" no Corone Mall - Serra/ES', 'location': 'Corone Mall - Serra , ES', 'date': '2025-06-06T08:00:00', 'end_date': '2025-08-02T23:59:00', 'link': 'https://www.sympla.com.br/evento/titela-em-ai-dentu-no-corone-mall-serra-es/2988972', 'image': 'https://images.sympla.com.br/6841f7c9c25f3-xs.jpg', 'font': 'Sympla', 'category': 'Outros', 'UF': 'ES', '_id': ObjectId('68535cb8c2bcc3b24a12bba5')}}], 'writeConcernErrors': [], 'nInserted': 209, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}
Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 13, in run_event_scraping_job
    scrape_and_save_events_sympla() # Call your main scraping function
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 226, in scrape_and_save_events_sympla
    save_events_bulk(all_events_to_save)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\database\db_operations.py", line 31, in save_events_bulk
    events_collection.insert_many(new_events)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\_csot.py", line 125, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\collection.py", line 975, in insert_many
    blk.execute(write_concern, session, _Op.INSERT)
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\bulk.py", line 751, in execute
    return self.execute_command(generator, write_concern, session, operation)
           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\synchronous\bulk.py", line 614, in execute_command
    _raise_bulk_write_error(full_result)
    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\pymongo\bulk_shared.py", line 131, in _raise_bulk_write_error
    raise BulkWriteError(full_result)
pymongo.errors.BulkWriteError: batch op errors occurred, full error: {'writeErrors': [{'index': 209, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: eventES.events index: link_1 dup key: { link: "https://www.sympla.com.br/evento/titela-em-ai-dentu-no-corone-mall-serra-es/2988972" }', 'keyPattern': {'link': 1}, 'keyValue': {'link': 'https://www.sympla.com.br/evento/titela-em-ai-dentu-no-corone-mall-serra-es/2988972'}, 'op': {'title': 'Titela em "AÍ DENTU" no Corone Mall - Serra/ES', 'location': 'Corone Mall - Serra , ES', 'date': '2025-06-06T08:00:00', 'end_date': '2025-08-02T23:59:00', 'link': 'https://www.sympla.com.br/evento/titela-em-ai-dentu-no-corone-mall-serra-es/2988972', 'image': 'https://images.sympla.com.br/6841f7c9c25f3-xs.jpg', 'font': 'Sympla', 'category': 'Outros', 'UF': 'ES', '_id': ObjectId('68535cb8c2bcc3b24a12bba5')}}], 'writeConcernErrors': [], 'nInserted': 209, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}
2025-06-18 21:41:31,665 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-18 21:51:50,442 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-18 21:52:50,477 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 21:53:00,702 - event_scraper_log - INFO - Event scraping SYMPLA job completed successfully.
2025-06-18 21:54:00,733 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-18 21:54:01,404 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-19 09:33:52,084 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-19 09:34:52,170 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 09:35:09,195 - event_scraper_log - INFO - Event scraping SYMPLA job completed successfully.
2025-06-19 09:35:12,372 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-19 09:35:16,956 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-19 09:35:31,837 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-19 09:36:31,875 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 09:36:38,494 - event_scraper_log - INFO - Event scraping SYMPLA job completed successfully.
2025-06-19 09:36:41,054 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-19 09:36:56,345 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-19 09:37:50,784 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-19 09:38:50,831 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 09:38:53,419 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-19 09:39:53,452 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 09:39:56,949 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-19 09:40:18,159 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-19 09:40:30,311 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-19 09:41:30,345 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 09:41:34,115 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-19 09:42:34,148 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 09:42:37,320 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-19 13:06:40,738 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-19 13:07:40,772 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 13:07:43,311 - event_scraper_log - INFO - Event scraping PATRICK RIBEIRO job completed successfully.
2025-06-19 13:07:54,578 - event_scraper_log - INFO - Event scraping MAPA CULTURAL job completed successfully.
2025-06-19 13:08:04,029 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-19 13:11:46,737 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-19 13:12:46,777 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 13:12:58,209 - event_scraper_log - INFO - Event scraping MAPA CULTURAL job completed successfully.
2025-06-19 13:13:48,368 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-19 13:42:32,331 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-19 13:43:32,364 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 13:43:40,988 - event_scraper_log - INFO - Event scraping Beacons events job completed successfully.
2025-06-19 13:43:55,992 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-19 14:25:56,163 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-19 14:26:56,197 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 14:26:56,288 - event_scraper_log - INFO - Event scraping CRA-ES job completed successfully.
2025-06-19 14:27:13,137 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-19 14:27:24,136 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-19 14:28:24,171 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 14:28:24,299 - event_scraper_log - INFO - Event scraping CRA-ES job completed successfully.
2025-06-19 14:28:32,821 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-19 14:31:23,719 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-19 14:32:23,761 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 14:32:25,199 - event_scraper_log - INFO - Event scraping CRA-ES job completed successfully.
2025-06-19 14:32:36,609 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-19 14:36:21,480 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-19 14:37:21,515 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 14:37:23,870 - event_scraper_log - INFO - Event scraping CRA-ES job completed successfully.
2025-06-19 14:37:27,975 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-19 14:48:20,838 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-19 14:49:20,918 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 14:49:27,594 - event_scraper_log - ERROR - Error during event scraping job: Could not reach host. Are you offline?
Traceback (most recent call last):
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\urllib3\connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
    ~~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\urllib3\connectionpool.py", line 1093, in _validate_conn
    conn.connect()
    ~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\urllib3\connection.py", line 741, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
        sock=sock,
    ...<14 lines>...
        assert_fingerprint=self.assert_fingerprint,
    )
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\urllib3\connection.py", line 920, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
        sock=sock,
    ...<8 lines>...
        tls_in_tls=tls_in_tls,
    )
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\urllib3\util\ssl_.py", line 480, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\urllib3\util\ssl_.py", line 524, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Local\Programs\Python\Python313\Lib\ssl.py", line 455, in wrap_socket
    return self.sslsocket_class._create(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        sock=sock,
        ^^^^^^^^^^
    ...<5 lines>...
        session=session
        ^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Luciano.Horta\AppData\Local\Programs\Python\Python313\Lib\ssl.py", line 1076, in _create
    self.do_handshake()
    ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Local\Programs\Python\Python313\Lib\ssl.py", line 1372, in do_handshake
    self._sslobj.do_handshake()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1028)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\urllib3\connectionpool.py", line 488, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1028)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\requests\adapters.py", line 667, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\urllib3\util\retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='googlechromelabs.github.io', port=443): Max retries exceeded with url: /chrome-for-testing/latest-patch-versions-per-build.json (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1028)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\webdriver_manager\core\http.py", line 32, in get
    resp = requests.get(
        url=url, verify=self._ssl_verify, stream=True, **kwargs)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\requests\adapters.py", line 698, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='googlechromelabs.github.io', port=443): Max retries exceeded with url: /chrome-for-testing/latest-patch-versions-per-build.json (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1028)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 37, in run_event_scraping_job
    scrape_zig_tickets()
    ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 784, in scrape_zig_tickets
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
                                              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\webdriver_manager\chrome.py", line 40, in install
    driver_path = self._get_driver_binary_path(self.driver)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\webdriver_manager\core\manager.py", line 35, in _get_driver_binary_path
    binary_path = self._cache_manager.find_driver(driver)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\webdriver_manager\core\driver_cache.py", line 107, in find_driver
    driver_version = self.get_cache_key_driver_version(driver)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\webdriver_manager\core\driver_cache.py", line 154, in get_cache_key_driver_version
    return driver.get_driver_version_to_download()
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\webdriver_manager\core\driver.py", line 48, in get_driver_version_to_download
    return self.get_latest_release_version()
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\webdriver_manager\drivers\chrome.py", line 59, in get_latest_release_version
    response = self._http_client.get(url)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\webdriver_manager\core\http.py", line 35, in get
    raise exceptions.ConnectionError(f"Could not reach host. Are you offline?")
requests.exceptions.ConnectionError: Could not reach host. Are you offline?
2025-06-19 14:49:46,522 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-19 14:51:05,654 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-19 14:52:05,696 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 14:52:28,472 - event_scraper_log - INFO - Event scraping CRA-ES job completed successfully.
2025-06-19 14:52:51,705 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-19 14:54:48,806 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-19 14:55:48,849 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 14:55:48,851 - event_scraper_log - ERROR - Error during event scraping job: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
Traceback (most recent call last):
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 64, in _binary_paths
    raise ValueError(f"The path is not a valid file: {path}")
ValueError: The path is not a valid file: C:/path/to/your/chromedriver.exe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 37, in run_event_scraping_job
    scrape_zig_tickets()
    ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 794, in scrape_zig_tickets
    driver = webdriver.Chrome(service=service, options=options)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\chrome\webdriver.py", line 47, in __init__
    super().__init__(
    ~~~~~~~~~~~~~~~~^
        browser_name=DesiredCapabilities.CHROME["browserName"],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        keep_alive=keep_alive,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\chromium\webdriver.py", line 53, in __init__
    if finder.get_browser_path():
       ~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 47, in get_browser_path
    return self._binary_paths()["browser_path"]
           ~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 78, in _binary_paths
    raise NoSuchDriverException(msg) from err
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location

2025-06-19 14:56:48,925 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 14:56:48,927 - event_scraper_log - ERROR - Error during event scraping job: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
Traceback (most recent call last):
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 64, in _binary_paths
    raise ValueError(f"The path is not a valid file: {path}")
ValueError: The path is not a valid file: C:/path/to/your/chromedriver.exe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 37, in run_event_scraping_job
    scrape_zig_tickets()
    ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 794, in scrape_zig_tickets
    driver = webdriver.Chrome(service=service, options=options)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\chrome\webdriver.py", line 47, in __init__
    super().__init__(
    ~~~~~~~~~~~~~~~~^
        browser_name=DesiredCapabilities.CHROME["browserName"],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        keep_alive=keep_alive,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\chromium\webdriver.py", line 53, in __init__
    if finder.get_browser_path():
       ~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 47, in get_browser_path
    return self._binary_paths()["browser_path"]
           ~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 78, in _binary_paths
    raise NoSuchDriverException(msg) from err
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location

2025-06-19 14:57:48,976 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 14:57:48,979 - event_scraper_log - ERROR - Error during event scraping job: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
Traceback (most recent call last):
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 64, in _binary_paths
    raise ValueError(f"The path is not a valid file: {path}")
ValueError: The path is not a valid file: C:/path/to/your/chromedriver.exe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 37, in run_event_scraping_job
    scrape_zig_tickets()
    ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 794, in scrape_zig_tickets
    driver = webdriver.Chrome(service=service, options=options)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\chrome\webdriver.py", line 47, in __init__
    super().__init__(
    ~~~~~~~~~~~~~~~~^
        browser_name=DesiredCapabilities.CHROME["browserName"],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        keep_alive=keep_alive,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\chromium\webdriver.py", line 53, in __init__
    if finder.get_browser_path():
       ~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 47, in get_browser_path
    return self._binary_paths()["browser_path"]
           ~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 78, in _binary_paths
    raise NoSuchDriverException(msg) from err
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location

2025-06-19 14:58:49,020 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 14:58:49,022 - event_scraper_log - ERROR - Error during event scraping job: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
Traceback (most recent call last):
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 64, in _binary_paths
    raise ValueError(f"The path is not a valid file: {path}")
ValueError: The path is not a valid file: C:/path/to/your/chromedriver.exe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 37, in run_event_scraping_job
    scrape_zig_tickets()
    ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 794, in scrape_zig_tickets
    driver = webdriver.Chrome(service=service, options=options)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\chrome\webdriver.py", line 47, in __init__
    super().__init__(
    ~~~~~~~~~~~~~~~~^
        browser_name=DesiredCapabilities.CHROME["browserName"],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        keep_alive=keep_alive,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\chromium\webdriver.py", line 53, in __init__
    if finder.get_browser_path():
       ~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 47, in get_browser_path
    return self._binary_paths()["browser_path"]
           ~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 78, in _binary_paths
    raise NoSuchDriverException(msg) from err
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location

2025-06-19 14:59:49,069 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 14:59:49,071 - event_scraper_log - ERROR - Error during event scraping job: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
Traceback (most recent call last):
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 64, in _binary_paths
    raise ValueError(f"The path is not a valid file: {path}")
ValueError: The path is not a valid file: C:/path/to/your/chromedriver.exe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 37, in run_event_scraping_job
    scrape_zig_tickets()
    ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 794, in scrape_zig_tickets
    driver = webdriver.Chrome(service=service, options=options)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\chrome\webdriver.py", line 47, in __init__
    super().__init__(
    ~~~~~~~~~~~~~~~~^
        browser_name=DesiredCapabilities.CHROME["browserName"],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        keep_alive=keep_alive,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\chromium\webdriver.py", line 53, in __init__
    if finder.get_browser_path():
       ~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 47, in get_browser_path
    return self._binary_paths()["browser_path"]
           ~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 78, in _binary_paths
    raise NoSuchDriverException(msg) from err
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location

2025-06-19 15:00:49,136 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 15:00:49,137 - event_scraper_log - ERROR - Error during event scraping job: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
Traceback (most recent call last):
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 64, in _binary_paths
    raise ValueError(f"The path is not a valid file: {path}")
ValueError: The path is not a valid file: C:/path/to/your/chromedriver.exe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 37, in run_event_scraping_job
    scrape_zig_tickets()
    ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 794, in scrape_zig_tickets
    driver = webdriver.Chrome(service=service, options=options)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\chrome\webdriver.py", line 47, in __init__
    super().__init__(
    ~~~~~~~~~~~~~~~~^
        browser_name=DesiredCapabilities.CHROME["browserName"],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        keep_alive=keep_alive,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\chromium\webdriver.py", line 53, in __init__
    if finder.get_browser_path():
       ~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 47, in get_browser_path
    return self._binary_paths()["browser_path"]
           ~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 78, in _binary_paths
    raise NoSuchDriverException(msg) from err
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location

2025-06-19 15:01:49,187 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 15:01:49,192 - event_scraper_log - ERROR - Error during event scraping job: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
Traceback (most recent call last):
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 64, in _binary_paths
    raise ValueError(f"The path is not a valid file: {path}")
ValueError: The path is not a valid file: C:/path/to/your/chromedriver.exe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 37, in run_event_scraping_job
    scrape_zig_tickets()
    ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 794, in scrape_zig_tickets
    driver = webdriver.Chrome(service=service, options=options)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\chrome\webdriver.py", line 47, in __init__
    super().__init__(
    ~~~~~~~~~~~~~~~~^
        browser_name=DesiredCapabilities.CHROME["browserName"],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        keep_alive=keep_alive,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\chromium\webdriver.py", line 53, in __init__
    if finder.get_browser_path():
       ~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 47, in get_browser_path
    return self._binary_paths()["browser_path"]
           ~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 78, in _binary_paths
    raise NoSuchDriverException(msg) from err
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location

2025-06-19 15:02:49,264 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 15:02:49,272 - event_scraper_log - ERROR - Error during event scraping job: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
Traceback (most recent call last):
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 64, in _binary_paths
    raise ValueError(f"The path is not a valid file: {path}")
ValueError: The path is not a valid file: C:/path/to/your/chromedriver.exe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 37, in run_event_scraping_job
    scrape_zig_tickets()
    ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 794, in scrape_zig_tickets
    driver = webdriver.Chrome(service=service, options=options)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\chrome\webdriver.py", line 47, in __init__
    super().__init__(
    ~~~~~~~~~~~~~~~~^
        browser_name=DesiredCapabilities.CHROME["browserName"],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        keep_alive=keep_alive,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\chromium\webdriver.py", line 53, in __init__
    if finder.get_browser_path():
       ~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 47, in get_browser_path
    return self._binary_paths()["browser_path"]
           ~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 78, in _binary_paths
    raise NoSuchDriverException(msg) from err
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location

2025-06-19 15:03:21,198 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-19 15:03:43,915 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-19 15:04:43,968 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 15:04:43,973 - event_scraper_log - ERROR - Error during event scraping job: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
Traceback (most recent call last):
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 64, in _binary_paths
    raise ValueError(f"The path is not a valid file: {path}")
ValueError: The path is not a valid file: C:/Users/Luciano.Horta/Documents/chromedriver.exe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 37, in run_event_scraping_job
    scrape_zig_tickets()
    ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 796, in scrape_zig_tickets
    driver = webdriver.Chrome(service=service, options=options)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\chrome\webdriver.py", line 47, in __init__
    super().__init__(
    ~~~~~~~~~~~~~~~~^
        browser_name=DesiredCapabilities.CHROME["browserName"],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        keep_alive=keep_alive,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\chromium\webdriver.py", line 53, in __init__
    if finder.get_browser_path():
       ~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 47, in get_browser_path
    return self._binary_paths()["browser_path"]
           ~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 78, in _binary_paths
    raise NoSuchDriverException(msg) from err
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location

2025-06-19 15:05:16,633 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-19 15:06:15,426 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-19 15:07:15,466 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 15:07:15,473 - event_scraper_log - ERROR - Error during event scraping job: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
Traceback (most recent call last):
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 64, in _binary_paths
    raise ValueError(f"The path is not a valid file: {path}")
ValueError: The path is not a valid file: C:/Users/Luciano.Horta/Documents/chromedriver.exe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 37, in run_event_scraping_job
    scrape_zig_tickets()
    ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 796, in scrape_zig_tickets
    driver = webdriver.Chrome(service=service, options=options)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\chrome\webdriver.py", line 47, in __init__
    super().__init__(
    ~~~~~~~~~~~~~~~~^
        browser_name=DesiredCapabilities.CHROME["browserName"],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        keep_alive=keep_alive,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\chromium\webdriver.py", line 53, in __init__
    if finder.get_browser_path():
       ~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 47, in get_browser_path
    return self._binary_paths()["browser_path"]
           ~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\selenium\webdriver\common\driver_finder.py", line 78, in _binary_paths
    raise NoSuchDriverException(msg) from err
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location

2025-06-19 15:07:23,230 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-19 15:09:16,691 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-19 15:10:16,723 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-19 15:11:39,983 - event_scraper_log - INFO - Event scraping CRA-ES job completed successfully.
2025-06-19 15:11:42,651 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-20 10:12:44,991 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-20 10:13:45,028 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-20 10:13:57,628 - event_scraper_log - INFO - Event scraping Beacons events job completed successfully.
2025-06-20 10:14:03,867 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-20 10:17:31,983 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-20 10:18:32,020 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-20 10:18:37,440 - event_scraper_log - INFO - Event scraping Beacons events job completed successfully.
2025-06-20 10:18:55,725 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-20 10:28:34,616 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-20 10:29:06,418 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-20 10:29:25,334 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-20 10:30:25,364 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-20 10:30:31,344 - event_scraper_log - INFO - Event scraping Beacons events job completed successfully.
2025-06-20 10:31:31,381 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-20 10:31:37,386 - event_scraper_log - INFO - Event scraping Beacons events job completed successfully.
2025-06-20 10:32:08,309 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-20 10:32:15,681 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-20 10:33:15,724 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-20 10:33:21,753 - event_scraper_log - INFO - Event scraping Beacons events job completed successfully.
2025-06-20 10:33:37,187 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-20 10:35:36,018 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-20 10:36:36,049 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-20 10:36:47,541 - event_scraper_log - INFO - Event scraping Beacons events job completed successfully.
2025-06-20 10:36:57,846 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-20 10:48:22,807 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-20 10:49:22,839 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-20 10:49:29,446 - event_scraper_log - INFO - Event scraping Beacons events job completed successfully.
2025-06-20 10:50:10,283 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-20 11:12:46,395 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-20 11:13:46,438 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-20 11:13:46,537 - event_scraper_log - ERROR - Error during event scraping job: HTTPSConnectionPool(host='www.es.senac.br', port=443): Max retries exceeded with url: /cursos?pagina=1&ordem=proximasturmas-desc&per_page=10 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1028)')))
Traceback (most recent call last):
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\urllib3\connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
    ~~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\urllib3\connectionpool.py", line 1093, in _validate_conn
    conn.connect()
    ~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\urllib3\connection.py", line 741, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
        sock=sock,
    ...<14 lines>...
        assert_fingerprint=self.assert_fingerprint,
    )
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\urllib3\connection.py", line 920, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
        sock=sock,
    ...<8 lines>...
        tls_in_tls=tls_in_tls,
    )
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\urllib3\util\ssl_.py", line 480, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\urllib3\util\ssl_.py", line 524, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Local\Programs\Python\Python313\Lib\ssl.py", line 455, in wrap_socket
    return self.sslsocket_class._create(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        sock=sock,
        ^^^^^^^^^^
    ...<5 lines>...
        session=session
        ^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Luciano.Horta\AppData\Local\Programs\Python\Python313\Lib\ssl.py", line 1076, in _create
    self.do_handshake()
    ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Luciano.Horta\AppData\Local\Programs\Python\Python313\Lib\ssl.py", line 1372, in do_handshake
    self._sslobj.do_handshake()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1028)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\urllib3\connectionpool.py", line 488, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1028)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\requests\adapters.py", line 667, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\urllib3\util\retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.es.senac.br', port=443): Max retries exceeded with url: /cursos?pagina=1&ordem=proximasturmas-desc&per_page=10 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1028)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\main.py", line 47, in run_event_scraping_job
    scrape_senac_courses()
    ~~~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\Luciano.Horta\Documents\Luciano\Projects\jobscheduler\scraper\event_scraper.py", line 898, in scrape_senac_courses
    response = requests.get(COURSE_LIST_URL)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Luciano.Horta\AppData\Roaming\Python\Python313\site-packages\requests\adapters.py", line 698, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.es.senac.br', port=443): Max retries exceeded with url: /cursos?pagina=1&ordem=proximasturmas-desc&per_page=10 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1028)')))
2025-06-20 11:14:16,391 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-20 11:17:21,969 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-20 11:18:22,005 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-20 11:18:31,728 - event_scraper_log - INFO - Event scraping Senac Courses job completed successfully.
2025-06-20 11:19:07,445 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-20 11:21:09,957 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-20 11:22:09,992 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-20 11:22:53,744 - event_scraper_log - INFO - Event scraping Senac Courses job completed successfully.
2025-06-20 11:22:56,857 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-20 12:22:41,233 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-20 12:23:41,271 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-20 12:24:27,109 - event_scraper_log - INFO - Event scraping Senac Courses job completed successfully.
2025-06-20 12:24:30,628 - event_scraper_log - INFO - Scheduler stopped by user.
2025-06-20 13:20:15,800 - event_scraper_log - INFO - Event scraper scheduler started. Waiting for next scheduled run.
2025-06-20 13:21:15,848 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-20 13:22:19,450 - event_scraper_log - INFO - Event scraping Senac Courses job completed successfully.
2025-06-20 13:23:19,485 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-20 13:24:27,704 - event_scraper_log - INFO - Event scraping Senac Courses job completed successfully.
2025-06-20 13:25:27,740 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-20 13:26:34,181 - event_scraper_log - INFO - Event scraping Senac Courses job completed successfully.
2025-06-20 13:27:34,229 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-20 13:28:32,898 - event_scraper_log - INFO - Event scraping Senac Courses job completed successfully.
2025-06-20 13:29:32,969 - event_scraper_log - INFO - Starting scheduled event scraping job...
2025-06-20 13:30:33,528 - event_scraper_log - INFO - Event scraping Senac Courses job completed successfully.
2025-06-20 13:30:54,602 - event_scraper_log - INFO - Scheduler stopped by user.
